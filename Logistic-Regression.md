## ğŸ“Š Logistic Regression 

## ğŸ” Definition

**Logistic Regression** is a **supervised machine learning algorithm** used for **classification problems**, where the output is **categorical (mostly binary)**.

ğŸ‘‰ Even though itâ€™s called *regression*, it is used for **classification**, not continuous prediction.

---

## ğŸ§  Core Idea (One Line)

> Logistic Regression predicts the **probability** that an input belongs to a particular class using the **Sigmoid function**.

---

## ğŸ“ Mathematical Model

### Linear Equation

[
z = b_0 + b_1x_1 + b_2x_2 + \dots + b_nx_n
]

### Sigmoid (Logistic) Function

[
\sigma(z) = \frac{1}{1 + e^{-z}}
]

ğŸ“Œ Output range: **0 to 1** (probability)

---

## ğŸ§® Decision Rule

* If **probability â‰¥ 0.5 â†’ Class 1**
* If **probability < 0.5 â†’ Class 0**

(Threshold can be changed depending on the problem)

---

## ğŸ§  How Logistic Regression Works (Step-by-Step)

1ï¸âƒ£ Take labeled data (X, Y)
2ï¸âƒ£ Compute linear combination (z)
3ï¸âƒ£ Apply sigmoid function
4ï¸âƒ£ Get probability value
5ï¸âƒ£ Compare with threshold
6ï¸âƒ£ Classify the output
7ï¸âƒ£ Update weights using **Gradient Descent**

---

## ğŸ“Š Cost Function (Very Important)

### Log Loss / Binary Cross-Entropy

[
J = -\frac{1}{n} \sum [y\log(p) + (1-y)\log(1-p)]
]

ğŸ¯ Goal: **Minimize Log Loss**

---

## ğŸ“Œ Why Not Mean Squared Error?

* Sigmoid makes MSE non-convex
* Log loss ensures **faster and stable convergence**

---

## ğŸ§  Types of Logistic Regression

### 1ï¸âƒ£ Binary Logistic Regression

* Two classes (0 / 1)
* Example: Spam / Not Spam

### 2ï¸âƒ£ Multinomial Logistic Regression

* More than two classes
* Example: Digit classification (0â€“9)

### 3ï¸âƒ£ Ordinal Logistic Regression

* Ordered classes
* Example: Low, Medium, High

---

## ğŸ“Š Performance Metrics

* Accuracy
* Precision
* Recall
* F1-Score
* ROC-AUC

---

## ğŸ§ª Real-World Examples

* Email spam detection
* Disease diagnosis (Yes / No)
* Fraud detection
* Customer churn prediction

---

## ğŸ“Œ Assumptions of Logistic Regression (Exam-Important)

1. Binary or categorical output
2. Independent observations
3. Little or no multicollinearity
4. Linear relationship between features and **log-odds**

---

## âœ… Advantages

âœ” Simple & fast
âœ” Probabilistic output
âœ” Easy to interpret
âœ” Works well for linearly separable data

---

## âŒ Disadvantages

âŒ Not suitable for non-linear boundaries
âŒ Sensitive to outliers
âŒ Requires feature scaling

---

## ğŸ§  One-Line Interview Answer

> **Logistic Regression is a supervised classification algorithm that uses the sigmoid function to predict probabilities and classify data into categories.**



